{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba3662f9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-23T15:43:29.450857Z",
     "iopub.status.busy": "2022-12-23T15:43:29.449399Z",
     "iopub.status.idle": "2022-12-23T15:43:37.878422Z",
     "shell.execute_reply": "2022-12-23T15:43:37.876898Z"
    },
    "papermill": {
     "duration": 8.440494,
     "end_time": "2022-12-23T15:43:37.882001",
     "exception": false,
     "start_time": "2022-12-23T15:43:29.441507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cedaa614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T15:43:37.892864Z",
     "iopub.status.busy": "2022-12-23T15:43:37.891995Z",
     "iopub.status.idle": "2022-12-23T15:43:53.504033Z",
     "shell.execute_reply": "2022-12-23T15:43:53.502360Z"
    },
    "papermill": {
     "duration": 15.620884,
     "end_time": "2022-12-23T15:43:53.507310",
     "exception": false,
     "start_time": "2022-12-23T15:43:37.886426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "['im selfish impatient and a little insecure i make mistakes i am out of control and at times hard to handle but if you cant handle me at my worst then you sure as hell dont deserve me at my best'\n",
      " 'youve gotta dance like theres nobody watchinglove like youll never be hurtsing like theres nobody listeningand live like its heaven on earth'\n",
      " 'you know youre in love when you cant fall asleep because reality is finally better than your dreams']\n"
     ]
    }
   ],
   "source": [
    "ds = pd.read_csv(\"/kaggle/input/quotes-500k/quotes.csv\")\n",
    "\n",
    "ds.head()\n",
    "\n",
    "ds = ds.drop(columns=[\"author\", \"category\"], axis=1)\n",
    "\n",
    "ds = np.array(ds)\n",
    "ds = ds.T[0].astype(str)\n",
    "\n",
    "ds = ds[0:10000]\n",
    "\n",
    "ds = np.char.lower(ds)\n",
    "\n",
    "ds = np.array(list(map(lambda x: re.sub(\"[^a-z0-9\\s]+\", \"\", x), ds)))\n",
    "\n",
    "print(ds.shape)\n",
    "print(ds[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd9d24f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T15:43:53.517590Z",
     "iopub.status.busy": "2022-12-23T15:43:53.517072Z",
     "iopub.status.idle": "2022-12-23T15:43:53.642718Z",
     "shell.execute_reply": "2022-12-23T15:43:53.640997Z"
    },
    "papermill": {
     "duration": 0.134317,
     "end_time": "2022-12-23T15:43:53.645495",
     "exception": false,
     "start_time": "2022-12-23T15:43:53.511178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 3786\n"
     ]
    }
   ],
   "source": [
    "lens = np.array(list(map(len, ds)))\n",
    "\n",
    "median_length = np.median(lens).astype(np.int32)\n",
    "max_length = np.amax(lens).astype(np.int32)\n",
    "\n",
    "print(median_length, max_length)\n",
    "\n",
    "# ds[291945]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8be5fce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T15:43:53.656355Z",
     "iopub.status.busy": "2022-12-23T15:43:53.655312Z",
     "iopub.status.idle": "2022-12-23T15:43:55.107200Z",
     "shell.execute_reply": "2022-12-23T15:43:55.105839Z"
    },
    "papermill": {
     "duration": 1.462033,
     "end_time": "2022-12-23T15:43:55.111718",
     "exception": false,
     "start_time": "2022-12-23T15:43:53.649685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "['\\t', ' ', '0', '1', '2', '3', '4', '5', '6', '7']\n",
      "[20 17 24 24 27]\n",
      "[b'h' b'e' b'l' b'l' b'o']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:43:55.036489: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "max_tokens = 10000\n",
    "\n",
    "vocab = sorted(set(\"\".join(ds)))\n",
    "vocab_size = len(vocab) + 1\n",
    "\n",
    "string_lookup = tf.keras.layers.StringLookup(max_tokens=max_tokens, vocabulary=vocab, mask_token=None)\n",
    "ids_lookup = tf.keras.layers.StringLookup(vocabulary=string_lookup.get_vocabulary(), invert=True, mask_token=None)\n",
    "\n",
    "print(len(vocab))\n",
    "print(vocab[0:10])\n",
    "\n",
    "string = np.array([\"h\", \"e\", \"l\", \"l\", \"o\"])\n",
    "ids = string_lookup(string)\n",
    "\n",
    "chars = ids_lookup(ids)\n",
    "print(ids.numpy())\n",
    "print(chars.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c75618c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T15:43:55.122058Z",
     "iopub.status.busy": "2022-12-23T15:43:55.121516Z",
     "iopub.status.idle": "2022-12-23T15:44:14.716610Z",
     "shell.execute_reply": "2022-12-23T15:44:14.714594Z"
    },
    "papermill": {
     "duration": 19.603894,
     "end_time": "2022-12-23T15:44:14.719757",
     "exception": false,
     "start_time": "2022-12-23T15:43:55.115863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n",
      "2022-12-23 15:44:14.233518: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(64, 114), dtype=int32, numpy=\n",
      "array([[31, 20, 13, ..., 14, 33, 16],\n",
      "       [20, 27, 35, ...,  0,  0,  0],\n",
      "       [24, 27, 34, ...,  0,  0,  0],\n",
      "       ...,\n",
      "       [13, 26, 16, ..., 21, 31,  2],\n",
      "       [21,  2, 35, ..., 20,  2, 24],\n",
      "       [35, 17, 24, ..., 25, 13, 16]], dtype=int32)>, <tf.Tensor: shape=(64, 114), dtype=int32, numpy=\n",
      "array([[20, 13, 24, ..., 33, 16, 31],\n",
      "       [27, 35,  2, ...,  0,  0,  0],\n",
      "       [27, 34, 17, ...,  0,  0,  0],\n",
      "       ...,\n",
      "       [26, 16,  2, ..., 31,  2, 21],\n",
      "       [ 2, 35, 13, ...,  2, 24, 27],\n",
      "       [17, 24, 24, ..., 13, 16, 17]], dtype=int32)>)\n",
      "(2, 64, 114)\n",
      "156\n"
     ]
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "    x = tf.strings.unicode_split(x, \"UTF-8\")\n",
    "    x = string_lookup(x)\n",
    "    return x.numpy()\n",
    "\n",
    "def pad(x):\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences(x, padding=\"post\", truncating=\"post\", maxlen=median_length)\n",
    "\n",
    "def split_input_sequence(x):\n",
    "    input_text = x[:-1]\n",
    "    target_text = x[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = np.array(list(map(tokenize, ds)))\n",
    "\n",
    "dataset = pad(dataset)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "\n",
    "dataset = dataset.map(split_input_sequence)\n",
    "\n",
    "\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = (\n",
    "    dataset.shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "for x in dataset.take(1):\n",
    "    print(x)\n",
    "    print(np.array(x).shape)\n",
    "    \n",
    "print(sum(1 for _ in dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b58358c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T15:44:14.730996Z",
     "iopub.status.busy": "2022-12-23T15:44:14.730452Z",
     "iopub.status.idle": "2022-12-23T15:44:14.781183Z",
     "shell.execute_reply": "2022-12-23T15:44:14.779762Z"
    },
    "papermill": {
     "duration": 0.060423,
     "end_time": "2022-12-23T15:44:14.784651",
     "exception": false,
     "start_time": "2022-12-23T15:44:14.724228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QuotesModel(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, rnn_units):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.rnn = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.rnn.get_initial_state(x)\n",
    "        x, states = self.rnn(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        return x\n",
    "\n",
    "embedding_dim = 256\n",
    "rnn_units = 2048\n",
    "\n",
    "model = QuotesModel(embedding_dim, rnn_units)\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c9b1a9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T15:44:14.795493Z",
     "iopub.status.busy": "2022-12-23T15:44:14.795014Z",
     "iopub.status.idle": "2022-12-23T15:44:35.278180Z",
     "shell.execute_reply": "2022-12-23T15:44:35.276821Z"
    },
    "papermill": {
     "duration": 20.492457,
     "end_time": "2022-12-23T15:44:35.281548",
     "exception": false,
     "start_time": "2022-12-23T15:44:14.789091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 64, 114)\n",
      "Inputs:  (64, 114)\n",
      "Embedding:  (64, 114, 256)\n",
      "Dense:  (64, 114, 41)\n",
      "Y:  (64, 114, 41)\n"
     ]
    }
   ],
   "source": [
    "for x in dataset.take(1):\n",
    "#     x = np.array(x[0][0])\n",
    "#     print(x.shape)\n",
    "#     y = model.predict(x)\n",
    "#     print(y.shape)\n",
    "    print(np.array(x).shape)   \n",
    "    inputs = np.array(x[0])\n",
    "    print(\"Inputs: \", inputs.shape)\n",
    "    x = inputs\n",
    "    x = model.embedding(x)\n",
    "    print(\"Embedding: \", x.shape)\n",
    "    x = model.rnn(x)\n",
    "    # (64,127,2048)\n",
    "    x = model.dense(x[0])\n",
    "    print(\"Dense: \", x.shape)\n",
    "    \n",
    "    y = model.predict(inputs)\n",
    "    print(\"Y: \", y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c00633fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T15:44:35.292636Z",
     "iopub.status.busy": "2022-12-23T15:44:35.292144Z",
     "iopub.status.idle": "2022-12-23T20:41:28.905793Z",
     "shell.execute_reply": "2022-12-23T20:41:28.902213Z"
    },
    "papermill": {
     "duration": 17813.83037,
     "end_time": "2022-12-23T20:41:29.116452",
     "exception": false,
     "start_time": "2022-12-23T15:44:35.286082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "156/156 [==============================] - 1819s 12s/step - loss: 2.4841 - accuracy: 0.3789\n",
      "Epoch 2/10\n",
      "156/156 [==============================] - 1779s 11s/step - loss: 1.7568 - accuracy: 0.4792\n",
      "Epoch 3/10\n",
      "156/156 [==============================] - 1769s 11s/step - loss: 1.5605 - accuracy: 0.5338\n",
      "Epoch 4/10\n",
      "156/156 [==============================] - 1780s 11s/step - loss: 1.3951 - accuracy: 0.5795\n",
      "Epoch 5/10\n",
      "156/156 [==============================] - 1780s 11s/step - loss: 1.2667 - accuracy: 0.6172\n",
      "Epoch 6/10\n",
      "156/156 [==============================] - 1780s 11s/step - loss: 1.1714 - accuracy: 0.6447\n",
      "Epoch 7/10\n",
      "156/156 [==============================] - 1787s 11s/step - loss: 1.1010 - accuracy: 0.6645\n",
      "Epoch 8/10\n",
      "156/156 [==============================] - 1788s 11s/step - loss: 1.0454 - accuracy: 0.6798\n",
      "Epoch 9/10\n",
      "156/156 [==============================] - 1764s 11s/step - loss: 0.9966 - accuracy: 0.6936\n",
      "Epoch 10/10\n",
      "156/156 [==============================] - 1767s 11s/step - loss: 0.9511 - accuracy: 0.7058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9dc4f0ed10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "575e8c82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T20:41:29.329455Z",
     "iopub.status.busy": "2022-12-23T20:41:29.328288Z",
     "iopub.status.idle": "2022-12-23T20:41:30.621263Z",
     "shell.execute_reply": "2022-12-23T20:41:30.620100Z"
    },
    "papermill": {
     "duration": 1.404092,
     "end_time": "2022-12-23T20:41:30.624348",
     "exception": false,
     "start_time": "2022-12-23T20:41:29.220256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 1, 41)\n",
      "[[[ 1.8905189  -1.1919647   2.4091408  ... -2.8418636  -2.2466638\n",
      "   -1.2191489 ]]\n",
      "\n",
      " [[-0.81998533 -1.5942986   1.6863627  ... -1.5216067  -1.6356951\n",
      "   -1.896911  ]]\n",
      "\n",
      " [[-3.6063762  -3.0635989  -3.2264922  ... -1.6439639  -3.0954165\n",
      "   -3.440505  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.5982934  -4.8537297   3.711016   ... -3.5622747  -4.5389953\n",
      "   -3.5859728 ]]\n",
      "\n",
      " [[-3.6063764  -3.0635989  -3.226492   ... -1.6439639  -3.0954165\n",
      "   -3.440505  ]]\n",
      "\n",
      " [[-3.4479544  -2.6148796  -1.3478332  ... -3.322566   -3.260182\n",
      "   -2.3942966 ]]]\n",
      "[[ 1.8905189  -1.1919647   2.4091408  ... -2.8418636  -2.2466638\n",
      "  -1.2191489 ]\n",
      " [-0.81998533 -1.5942986   1.6863627  ... -1.5216067  -1.6356951\n",
      "  -1.896911  ]\n",
      " [-3.6063762  -3.0635989  -3.2264922  ... -1.6439639  -3.0954165\n",
      "  -3.440505  ]\n",
      " ...\n",
      " [ 1.5982934  -4.8537297   3.711016   ... -3.5622747  -4.5389953\n",
      "  -3.5859728 ]\n",
      " [-3.6063764  -3.0635989  -3.226492   ... -1.6439639  -3.0954165\n",
      "  -3.440505  ]\n",
      " [-3.4479544  -2.6148796  -1.3478332  ... -3.322566   -3.260182\n",
      "  -2.3942966 ]]\n"
     ]
    }
   ],
   "source": [
    "for x in dataset.take(1):\n",
    "    x = np.array(x[0][0])\n",
    "    y = model.predict(x)\n",
    "    print(y.shape)\n",
    "    print(y)\n",
    "    pred = y[:, -1, :]\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cdc7de5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T20:41:30.834270Z",
     "iopub.status.busy": "2022-12-23T20:41:30.833517Z",
     "iopub.status.idle": "2022-12-23T20:41:39.796119Z",
     "shell.execute_reply": "2022-12-23T20:41:39.795225Z"
    },
    "papermill": {
     "duration": 9.070194,
     "end_time": "2022-12-23T20:41:39.798807",
     "exception": false,
     "start_time": "2022-12-23T20:41:30.728613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'i only give you a ligar everyone has tanget what i wanted in the universe but thats not a fictionag vilveriescontrull than mincterate with being tround dont read it rather betwelf that think that im diconguops a circumatine lightnyangs alive stooked her that she said women the way you imentife it isnt run something from all the rest of mental intenjectively intentions may anywhere our two of the passive got no voice in the pare you can  ant rather toagh insomental when there would art it colleges back into high the worlds on the heat of an alghostic 1q adage2 zelentlature of your convaislick theyre not any slughttanders shigky braddus and dame wo dont mean  anysone that and not live youdlooking withraid me to called if you want to can lioted them sometimes i can no more than person but sleepingy waiting for as i need it she haz been goodal me which invitch my names at my animension special blem the papsles wize and pug how women are no mats with those servain knowy he said tex in the he'], shape=(1,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "class OneStepModel(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "        \n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            values=[-float(\"inf\")] * len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())],\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "        \n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        input_chars = tf.strings.unicode_split(inputs, \"UTF-8\")\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "        \n",
    "        predicted_logits, states = self.model(\n",
    "            inputs=input_ids, states=states, return_state=True\n",
    "        )\n",
    "        \n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        \n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "        \n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "            \n",
    "        return predicted_chars, states\n",
    "    \n",
    "    \n",
    "one_step_model = OneStepModel(model, ids_lookup, string_lookup)\n",
    "\n",
    "states = None\n",
    "\n",
    "next_char = tf.constant([\"i\"])\n",
    "\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "    \n",
    "result = tf.strings.join(result)\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17904.16764,
   "end_time": "2022-12-23T20:41:42.837795",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-23T15:43:18.670155",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
