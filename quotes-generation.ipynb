{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-12-24T19:45:33.706780Z","iopub.status.busy":"2022-12-24T19:45:33.706122Z","iopub.status.idle":"2022-12-24T19:45:41.931626Z","shell.execute_reply":"2022-12-24T19:45:41.930309Z","shell.execute_reply.started":"2022-12-24T19:45:33.706653Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import re\n","import random\n","\n","\n","print(\"Cuda Availability: \", tf.test.is_built_with_cuda())\n","print(\"Version of Tensorflow: \", tf.__version__)\n","print(\"GPU  Availability: \", tf.config.list_physical_devices('GPU'))\n","print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n","print(\"Built with CUDA: \", tf.test.is_built_with_cuda())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-24T19:47:06.058011Z","iopub.status.busy":"2022-12-24T19:47:06.057024Z","iopub.status.idle":"2022-12-24T19:47:47.819362Z","shell.execute_reply":"2022-12-24T19:47:47.817786Z","shell.execute_reply.started":"2022-12-24T19:47:06.057954Z"},"trusted":true},"outputs":[],"source":["INPUT = \"data/quotes.csv\"\n","# INPUT = \"/kaggle/input/quotes-500k/quotes.csv\"\n","\n","ds = pd.read_csv(INPUT)\n","\n","ds.head()\n","\n","ds = ds.drop(columns=[\"author\", \"category\"], axis=1)\n","\n","ds = np.array(ds)\n","ds = ds.T[0].astype(str)\n","\n","# ds = ds[0:1000]\n","\n","ds = np.char.lower(ds)\n","\n","ds = np.array(list(map(lambda x: re.sub(\"[^a-z0-9\\s]+\", \"\", x), ds)))\n","\n","print(ds.shape)\n","print(ds[0:3])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-24T20:21:39.379222Z","iopub.status.busy":"2022-12-24T20:21:39.378746Z","iopub.status.idle":"2022-12-24T20:21:45.491836Z","shell.execute_reply":"2022-12-24T20:21:45.490431Z","shell.execute_reply.started":"2022-12-24T20:21:39.379187Z"},"trusted":true},"outputs":[],"source":["print(ds.shape)\n","\n","MAX_LENGTH = 150\n","\n","def length_check(x):\n","    return len(x) < MAX_LENGTH\n","\n","ds = np.array(list(filter(length_check, ds)))\n","print(ds.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# fifty_most_common_words = [ \"the\", \"be\", \"of\", \"and\", \"a\", \"to\", \"in\", \"he\", \"have\", \"it\", \"that\", \"for\", \"they\", \"I\", \"with\", \"as\", \"not\", \"on\", \"she\", \"at\", \"by\", \"this\", \"we\", \"you\", \"do\", \"but\", \"from\", \"or\", \"which\", \"one\", \"would\", \"all\", \"will\", \"there\", \"say\", \"who\", \"make\", \"when\", \"can\", \"more\", \"if\", \"no\", \"man\", \"out\", \"other\", \"so\", \"what\", \"time\", \"up\", \"go\"]\n","\n","text = \" \".join(ds)\n","# def remove_fifty_most_common_words_from_text(text):\n","#     for word in fifty_most_common_words:\n","#         text = text.replace(word, \"\")\n","#     return text\n","\n","# text = remove_fifty_most_common_words_from_text(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-24T20:21:58.427305Z","iopub.status.busy":"2022-12-24T20:21:58.426780Z","iopub.status.idle":"2022-12-24T20:22:00.075463Z","shell.execute_reply":"2022-12-24T20:22:00.074463Z","shell.execute_reply.started":"2022-12-24T20:21:58.427267Z"},"trusted":true},"outputs":[],"source":["max_tokens = 20000\n","max_len = 400\n","\n","def letters(input):\n","    valids = []\n","    for character in input:\n","        if character.isalpha():\n","            valids.append(character)\n","    return ''.join(valids)\n","\n","\n","def more_than_once(input):\n","    if len(input) < 1:\n","        return False\n","    return text.count(input) > 6\n","words = text.split(\" \")\n","\n","words = list(set(words))\n","vocab = sorted(words)\n","\n","vocab = list(map(letters, vocab))\n","vocab = list(filter(lambda x: len(x) > 0, vocab))\n","vocab = list(set(vocab))\n","vocab = sorted(vocab)\n","\n","vocab = list(filter(more_than_once, vocab))\n","\n","print(len(vocab))\n","print(vocab[0:100])\n","print(vocab[-10:])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","vectorize_layer = tf.keras.layers.TextVectorization(\n","    max_tokens=None,\n","    output_mode=\"int\",\n","    output_sequence_length=max_len,\n","    vocabulary=vocab,\n",")\n","\n","vocab = vectorize_layer.get_vocabulary()\n","vocab[0] = \"[UNK]\"\n","vocab[1] = \"\"\n","vocab_size = len(vocab)\n","\n","print(vocab_size)\n","print(vocab[0:10])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lookup = tf.keras.layers.StringLookup(vocabulary=vocab, mask_token=None, invert=True)\n","\n","def undo_vectorize(text):\n","    return lookup(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-24T20:23:00.699807Z","iopub.status.busy":"2022-12-24T20:23:00.699354Z","iopub.status.idle":"2022-12-24T20:26:37.180208Z","shell.execute_reply":"2022-12-24T20:26:37.178970Z","shell.execute_reply.started":"2022-12-24T20:23:00.699770Z"},"trusted":true},"outputs":[],"source":["def pad(x):\n","    return tf.keras.preprocessing.sequence.pad_sequences(x, padding=\"post\", truncating=\"post\", maxlen=MAX_LENGTH)\n","\n","def split_input_sequence(x):\n","    input_text = x[:-1]\n","    target_text = x[1:]\n","    return input_text, target_text\n","\n","dataset = vectorize_layer(ds)\n","\n","dataset = pad(dataset)\n","\n","dataset = tf.data.Dataset.from_tensor_slices(dataset)\n","\n","dataset = dataset.map(split_input_sequence)\n","\n","BUFFER_SIZE = 1000\n","BATCH_SIZE = 128\n","\n","dataset = (\n","    dataset.shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE, drop_remainder=True)\n","    .prefetch(tf.data.experimental.AUTOTUNE)\n",")\n","\n","for x in dataset.take(1):\n","    print(x)\n","    print(np.array(x).shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-24T20:26:37.183254Z","iopub.status.busy":"2022-12-24T20:26:37.182778Z","iopub.status.idle":"2022-12-24T20:26:37.225926Z","shell.execute_reply":"2022-12-24T20:26:37.224673Z","shell.execute_reply.started":"2022-12-24T20:26:37.183204Z"},"trusted":true},"outputs":[],"source":["class QuotesModel(tf.keras.Model):\n","    def __init__(self, embedding_dim, rnn_units):\n","        super().__init__()\n","        \n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        \n","        self.rnn = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n","        \n","        self.dense = tf.keras.layers.Dense(vocab_size)\n","        \n","    def call(self, inputs, states=None, return_state=False, training=False):\n","        x = inputs\n","        x = self.embedding(x, training=training)\n","        if states is None:\n","            states = self.rnn.get_initial_state(x)\n","        x, states = self.rnn(x, initial_state=states, training=training)\n","        x = self.dense(x, training=training)\n","\n","        if return_state:\n","            return x, states\n","        return x\n","\n","embedding_dim = 1024\n","rnn_units = 2048\n","\n","model = QuotesModel(embedding_dim, rnn_units)\n","\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-24T20:26:37.229768Z","iopub.status.busy":"2022-12-24T20:26:37.227895Z"},"trusted":true},"outputs":[],"source":["EPOCHS = 10\n","model.fit(dataset, epochs=EPOCHS)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.save_weights(\"qgt-2\")\n","\n","# model = model.load_weights(\"qgt-2\")\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for x in dataset.take(1):\n","    x = np.array(x[0])\n","    print(x.shape)\n","    y = model.predict(x)\n","    print(y.shape)\n","    pred = y[:, -1, :]\n","    print(pred.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","\n","class OneStepModel(tf.keras.Model):\n","    def __init__(self, model):\n","        super().__init__()\n","        self.model = model\n","        self.chars_from_ids = undo_vectorize\n","        self.ids_from_chars = vectorize_layer\n","\n","        # skip_ids = self.ids_from_chars([\"[UNK]\"])[:, :]\n","        skip_ids = [[0]]\n","\n","        sparse_mask = tf.SparseTensor(\n","            values=[-float(\"inf\")] * len(skip_ids),\n","            indices=skip_ids,\n","            dense_shape=[len(vectorize_layer.get_vocabulary())],\n","        )\n","        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n","        \n","    @tf.function\n","    def generate_one_step(self, inputs, states=None):\n","        input_ids = self.ids_from_chars(inputs)\n","        predicted_logits, states = self.model(\n","            inputs=input_ids, states=states, return_state=True\n","        )\n","        predicted_logits = predicted_logits[:, -1, :]\n","        predicted_logits = predicted_logits + self.prediction_mask\n","        \n","        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n","        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n","        predicted_chars = self.chars_from_ids(predicted_ids)\n","        return predicted_chars, states\n","\n","one_step_model = OneStepModel(model)\n","\n","def generate_text(model, start_string, num_generate=1000):\n","    states = None\n","\n","    next_char = tf.constant([start_string])\n","\n","    result = [next_char]\n","\n","    for n in range(num_generate):\n","        next_char, states = model.generate_one_step(next_char, states=states) # type: ignore\n","        result.append(next_char)\n","\n","    result = tf.strings.join(result, separator=\" \")\n","    return result[0].numpy().decode(\"utf-8\")\n","\n","for i in range(10):\n","    word = random.choice(vocab)\n","    print(generate_text(one_step_model, start_string=\"chess\", num_generate=15), end=\"\\n\\n\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h1>Version 1.0 (QGT-1)</h1>\n","131728 data points (less than 75 characters)<br>\n","7961 vocab size (6 occurrences and up)<br>\n","10 Epochs\n","Acc: .89\n","\n","Noteworthy Quotes: <br>\n","\"Chess is a game of grace, and life is a game of chess; it is never too late to have grace, now or never\"<br>\n","\"The meaning of life may only be to cope with the lies spread by nerves, but cats seem to have it figured out.\"<br>\n","\"Guilt without glory isn't great, but my only purpose now is to do anything I can to make up for it.\"<br>\n","\"Cats may be buried, but they are not gone forever. They are somehow still alive and ignited within us, even if we cannot see them.\"<br>\n","\"Bliss may be more like the eternal life of trees, rather than the blood that flows through us. Not all of us are only awake and in pain.\"<br>\n","\"Innocence and guilt breathe life into our choices, carefully projecting the will to move forward. In the end, even John may be abandoned.\"<br>\n","\"The moon brings us to where we need to be, even if it isn't until afterward. Cats may not need leadership, but we do, and it is never too late to start again.\"<br>\n","\"Humanity may be facing reality now, but the method to their madness is forever a mystery, even to the cats who seem to have it all figured out.\"<br>\n","\"Bliss is a myth, more like more trees with eternal blood, though not all awake in pain\"<br>\n","\n","<h1>Version 2.0 (QGT-2)</h1>\n","352141 data points (less than 200 characters)<br>\n","30988 vocab size (50 most common words removed, 4 occurrences and up)<br>\n","10 Epochs<br>\n","Acc: .91\n","\n","Noteworthy Quotes: <br>\n","\n"]}],"metadata":{"kernelspec":{"display_name":"tf","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"vscode":{"interpreter":{"hash":"8617e9fe8133060aa348870c29ae13e07a357a339f371b8023b0704a656ebb67"}}},"nbformat":4,"nbformat_minor":4}
