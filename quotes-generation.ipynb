{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport re","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-24T19:45:33.706122Z","iopub.execute_input":"2022-12-24T19:45:33.706780Z","iopub.status.idle":"2022-12-24T19:45:41.931626Z","shell.execute_reply.started":"2022-12-24T19:45:33.706653Z","shell.execute_reply":"2022-12-24T19:45:41.930309Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"ds = pd.read_csv(\"/kaggle/input/quotes-500k/quotes.csv\")\n\nds.head()\n\nds = ds.drop(columns=[\"author\", \"category\"], axis=1)\n\nds = np.array(ds)\nds = ds.T[0].astype(str)\n\n# ds = ds[0:10000]\n\nds = np.char.lower(ds)\n\nds = np.array(list(map(lambda x: re.sub(\"[^a-z0-9\\s]+\", \"\", x), ds)))\n\nprint(ds.shape)\nprint(ds[0:3])","metadata":{"execution":{"iopub.status.busy":"2022-12-24T19:47:06.057024Z","iopub.execute_input":"2022-12-24T19:47:06.058011Z","iopub.status.idle":"2022-12-24T19:47:47.819362Z","shell.execute_reply.started":"2022-12-24T19:47:06.057954Z","shell.execute_reply":"2022-12-24T19:47:47.817786Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(499709,)\n['im selfish impatient and a little insecure i make mistakes i am out of control and at times hard to handle but if you cant handle me at my worst then you sure as hell dont deserve me at my best'\n 'youve gotta dance like theres nobody watchinglove like youll never be hurtsing like theres nobody listeningand live like its heaven on earth'\n 'you know youre in love when you cant fall asleep because reality is finally better than your dreams']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(ds.shape)\n\nMAX_LENGTH = 75\n\ndef length_check(x):\n    return len(x) < MAX_LENGTH\n\nda = np.array(list(filter(length_check, ds)))\nprint(da.shape)\n\nds = da","metadata":{"execution":{"iopub.status.busy":"2022-12-24T20:21:39.378746Z","iopub.execute_input":"2022-12-24T20:21:39.379222Z","iopub.status.idle":"2022-12-24T20:21:45.491836Z","shell.execute_reply.started":"2022-12-24T20:21:39.379187Z","shell.execute_reply":"2022-12-24T20:21:45.490431Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(499709,)\n(131728,)\n","output_type":"stream"}]},{"cell_type":"code","source":"lens = np.array(list(map(len, ds)))\n\nmedian_length = np.median(lens).astype(np.int32)\nmax_length = np.amax(lens).astype(np.int32)\n\nprint(median_length, max_length)\n\n# ds[291945]","metadata":{"execution":{"iopub.status.busy":"2022-12-24T20:21:46.762516Z","iopub.execute_input":"2022-12-24T20:21:46.763474Z","iopub.status.idle":"2022-12-24T20:21:46.841948Z","shell.execute_reply.started":"2022-12-24T20:21:46.763416Z","shell.execute_reply":"2022-12-24T20:21:46.840025Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"53 74\n","output_type":"stream"}]},{"cell_type":"code","source":"max_tokens = 10000\n\nvocab = sorted(set(\"\".join(ds)))\nvocab_size = len(vocab) + 1\n\nstring_lookup = tf.keras.layers.StringLookup(max_tokens=max_tokens, vocabulary=vocab, mask_token=None)\nids_lookup = tf.keras.layers.StringLookup(vocabulary=string_lookup.get_vocabulary(), invert=True, mask_token=None)\n\nprint(len(vocab))\nprint(vocab[0:10])\n\nstring = np.array([\"h\", \"e\", \"l\", \"l\", \"o\"])\nids = string_lookup(string)\n\nchars = ids_lookup(ids)\nprint(ids.numpy())\nprint(chars.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-12-24T20:21:58.426780Z","iopub.execute_input":"2022-12-24T20:21:58.427305Z","iopub.status.idle":"2022-12-24T20:22:00.075463Z","shell.execute_reply.started":"2022-12-24T20:21:58.427267Z","shell.execute_reply":"2022-12-24T20:22:00.074463Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"43\n['\\t', ' ', '0', '1', '2', '3', '4', '5', '6', '7']\n[20 17 24 24 27]\n[b'h' b'e' b'l' b'l' b'o']\n","output_type":"stream"},{"name":"stderr","text":"2022-12-24 20:22:00.003696: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize(x):\n    x = tf.strings.unicode_split(x, \"UTF-8\")\n    x = string_lookup(x)\n    return x.numpy()\n\ndef pad(x):\n    return tf.keras.preprocessing.sequence.pad_sequences(x, padding=\"post\", truncating=\"post\", maxlen=max_length)\n\ndef split_input_sequence(x):\n    input_text = x[:-1]\n    target_text = x[1:]\n    return input_text, target_text\n\ndataset = np.array(list(map(tokenize, ds)))\n\ndataset = pad(dataset)\n\ndataset = tf.data.Dataset.from_tensor_slices(dataset)\n\ndataset = dataset.map(split_input_sequence)\n\n\nBUFFER_SIZE = 1000\nBATCH_SIZE = 128\n\ndataset = (\n    dataset.shuffle(BUFFER_SIZE)\n    .batch(BATCH_SIZE, drop_remainder=True)\n    .prefetch(tf.data.experimental.AUTOTUNE)\n)\n\nfor x in dataset.take(1):\n    print(x)\n    print(np.array(x).shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-24T20:23:00.699354Z","iopub.execute_input":"2022-12-24T20:23:00.699807Z","iopub.status.idle":"2022-12-24T20:26:37.180208Z","shell.execute_reply.started":"2022-12-24T20:23:00.699770Z","shell.execute_reply":"2022-12-24T20:26:37.178970Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  \n","output_type":"stream"},{"name":"stdout","text":"(<tf.Tensor: shape=(128, 73), dtype=int32, numpy=\narray([[35, 20, 17, ...,  0,  0,  0],\n       [21,  2, 20, ...,  0,  0,  0],\n       [28, 30, 21, ...,  0,  0,  0],\n       ...,\n       [24, 27, 34, ...,  0,  0,  0],\n       [27, 26, 17, ...,  0,  0,  0],\n       [21, 18,  2, ...,  0,  0,  0]], dtype=int32)>, <tf.Tensor: shape=(128, 73), dtype=int32, numpy=\narray([[20, 17, 26, ...,  0,  0,  0],\n       [ 2, 20, 13, ...,  0,  0,  0],\n       [30, 21, 16, ...,  0,  0,  0],\n       ...,\n       [27, 34, 17, ...,  0,  0,  0],\n       [26, 17,  2, ...,  0,  0,  0],\n       [18,  2, 37, ...,  0,  0,  0]], dtype=int32)>)\n(2, 128, 73)\n","output_type":"stream"},{"name":"stderr","text":"2022-12-24 20:26:37.092141: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"class QuotesModel(tf.keras.Model):\n    def __init__(self, embedding_dim, rnn_units):\n        super().__init__()\n        \n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n        \n        self.rnn = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n        \n        self.dense = tf.keras.layers.Dense(vocab_size)\n        \n    def call(self, inputs, states=None, return_state=False, training=False):\n        x = inputs\n        x = self.embedding(x, training=training)\n        if states is None:\n            states = self.rnn.get_initial_state(x)\n        x, states = self.rnn(x, initial_state=states, training=training)\n        x = self.dense(x, training=training)\n\n        if return_state:\n            return x, states\n        return x\n\nembedding_dim = 256\nrnn_units = 2048\n\nmodel = QuotesModel(embedding_dim, rnn_units)\n\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\nmodel.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-12-24T20:26:37.182778Z","iopub.execute_input":"2022-12-24T20:26:37.183254Z","iopub.status.idle":"2022-12-24T20:26:37.225926Z","shell.execute_reply.started":"2022-12-24T20:26:37.183204Z","shell.execute_reply":"2022-12-24T20:26:37.224673Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for x in dataset.take(1):\n#     x = np.array(x[0][0])\n#     print(x.shape)\n#     y = model.predict(x)\n#     print(y.shape)\n    print(np.array(x).shape)   \n    inputs = np.array(x[0])\n    print(\"Inputs: \", inputs.shape)\n    x = inputs\n    x = model.embedding(x)\n    print(\"Embedding: \", x.shape)\n    x = model.rnn(x)\n    # (64,127,2048)\n    x = model.dense(x[0])\n    print(\"Dense: \", x.shape)\n    \n    y = model.predict(inputs)\n    print(\"Y: \", y.shape)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-23T23:25:50.670414Z","iopub.execute_input":"2022-12-23T23:25:50.670972Z","iopub.status.idle":"2022-12-23T23:26:03.010998Z","shell.execute_reply.started":"2022-12-23T23:25:50.670927Z","shell.execute_reply":"2022-12-23T23:26:03.009680Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"(2, 64, 114)\nInputs:  (64, 114)\nEmbedding:  (64, 114, 256)\nDense:  (64, 114, 41)\nY:  (64, 114, 41)\n","output_type":"stream"}]},{"cell_type":"code","source":"EPOCHS = 10\nmodel.fit(dataset, epochs=EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2022-12-24T20:26:37.227895Z","iopub.execute_input":"2022-12-24T20:26:37.229768Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n1029/1029 [==============================] - 10839s 11s/step - loss: 1.4007 - accuracy: 0.5929\nEpoch 2/10\n1029/1029 [==============================] - 10685s 10s/step - loss: 0.8738 - accuracy: 0.7308\nEpoch 3/10\n1029/1029 [==============================] - 10811s 11s/step - loss: 0.7880 - accuracy: 0.7552\nEpoch 4/10\n 783/1029 [=====================>........] - ETA: 43:16 - loss: 0.7485 - accuracy: 0.7666","output_type":"stream"}]},{"cell_type":"code","source":"for x in dataset.take(1):\n    x = np.array(x[0][0])\n    y = model.predict(x)\n    print(y.shape)\n    print(y)\n    pred = y[:, -1, :]\n    print(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class OneStepModel(tf.keras.Model):\n    def __init__(self, model, chars_from_ids, ids_from_chars):\n        super().__init__()\n        self.model = model\n        self.chars_from_ids = chars_from_ids\n        self.ids_from_chars = ids_from_chars\n        \n        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n\n        sparse_mask = tf.SparseTensor(\n            values=[-float(\"inf\")] * len(skip_ids),\n            indices=skip_ids,\n            dense_shape=[len(ids_from_chars.get_vocabulary())],\n        )\n        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n        \n    @tf.function\n    def generate_one_step(self, inputs, states=None):\n        input_chars = tf.strings.unicode_split(inputs, \"UTF-8\")\n        input_ids = self.ids_from_chars(input_chars).to_tensor()\n        \n        predicted_logits, states = self.model(\n            inputs=input_ids, states=states, return_state=True\n        )\n        \n        predicted_logits = predicted_logits[:, -1, :]\n        \n        predicted_logits = predicted_logits + self.prediction_mask\n        \n        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n        predicted_chars = self.chars_from_ids(predicted_ids)\n            \n        return predicted_chars, states\n    \n    \none_step_model = OneStepModel(model, ids_lookup, string_lookup)\n\nstates = None\n\nnext_char = tf.constant([\"i\"])\n\nresult = [next_char]\n\nfor n in range(1000):\n    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n    result.append(next_char)\n    \nresult = tf.strings.join(result)\n\nprint(result)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}